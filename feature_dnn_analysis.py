from models import TrivialDNN
import tensorflow as tf
from datasets import BinaryDataSet
from spektral.data import BatchLoader
import numpy as np
import gc



# Hyperparameters
LEARNING_RATE = 0.00004
EPOCHS = 30



# Create and compile the model
model = TrivialDNN()
model.compile(
    loss=tf.keras.losses.CategoricalCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    metrics=["accuracy"]
)

# Load and prepare the data
data = np.loadtxt("processed_data/cfg_dlssmc/data.txt").astype("float32")
np.random.shuffle(data)
training_data = data[0 : int(len(data)*0.8)]
testing_data = data[int(len(data)*0.8) : len(data)]

# Split the data
x_train = np.delete(training_data, np.shape(training_data)[1]-1, 1)
y_train = training_data[:,np.shape(training_data)[1]-1]
x_test = np.delete(testing_data, np.shape(testing_data)[1]-1, 1)
y_test = testing_data[:,np.shape(testing_data)[1]-1]

# I didn't save the labels as vectors, so I must convert it so I can use categorical cross entropy
y_train = np.array([[1,0] if i == 1 else [0,1] for i in y_train])
y_test = np.array([[1,0] if i == 1 else [0,1] for i in y_test])

# Normalize the data
mean = np.mean(x_train, axis=0)
std = np.std(x_train, axis=0)
x_train = (x_train - mean)/(std + 0.0001)
x_test = (x_test - mean)/(std + 0.0001)

# Train the model
model.fit(x_train, y_train, batch_size=1, epochs=EPOCHS, verbose=1)

# Test the model
loss = model.evaluate(x_test, y_test, batch_size=1)
print('Test loss: {}'.format(loss))