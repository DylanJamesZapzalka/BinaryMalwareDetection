import os
from spektral import data
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout
from spektral.layers import GCNConv, GlobalSumPool
from tensorflow.keras.layers import Dense, AlphaDropout
from spektral.datasets import TUDataset
from tensorflow.keras.layers import BatchNormalization, Input
from spektral.data import BatchLoader
import numpy as np
from matplotlib import pyplot as plt
import sys
from datasets import BinaryDataSet



np.set_printoptions(threshold=sys.maxsize)
dataset = BinaryDataSet()
print(dataset)
np.random.shuffle(dataset)
print(dataset.n_labels)
dataset_train = dataset[:1200]
dataset_test = dataset[1200:]

print("I made it here ;)")


class MyFirstGNN(Model):

    def __init__(self, n_hidden, n_labels):
        super().__init__()
        self.graph_conv_1 = GCNConv(n_hidden)
        self.dropout_1 = Dropout(0.5)
        self.pool = GlobalSumPool()
        self.dense = Dense(n_labels, 'softmax')
    
    def call(self, inputs):
        out = self.graph_conv_1(inputs)
        out = self.dropout_1(out)
        out = self.pool(out)

        out = self.dense(out)

        return out



model = MyFirstGNN(32, 2)
#model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# Compile the network
model.compile(
    loss=keras.losses.CategoricalCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    metrics=["accuracy"]
)


loader = BatchLoader(dataset_train, batch_size=1)
model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, epochs=20, verbose=2)

loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)
print(loss)
print('Test loss: {}'.format(loss))