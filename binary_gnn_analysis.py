from models import BinaryGNN
import tensorflow as tf
from datasets import BinaryDataSet
from spektral.data import BatchLoader
import numpy as np
import gc



# Hyperparameters
LEARNING_RATE = 0.00012
EPOCHS = 48

lr = tf.keras.optimizers.schedules.PolynomialDecay(
    LEARNING_RATE, end_learning_rate=0.000004, decay_steps=EPOCHS * 1571
)

# Create and compile the model
model = BinaryGNN()
model.compile(
    loss=tf.keras.losses.CategoricalCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),
    metrics=["accuracy"]
)

# Load the data
dataset = BinaryDataSet()
np.random.shuffle(dataset)
training_set = dataset[0 : int(len(dataset)*.8)]
testing_set = dataset[int(len(dataset)*.8) : len(dataset)]

# Train the model
loader = BatchLoader(training_set)
model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, epochs=EPOCHS, verbose=1)

# Test the model
loader = BatchLoader(testing_set, shuffle=False)

actuals = [0 if i.y[0] == 1 else 1 for i in loader.load().dataset.graphs]

predictions = model.predict(loader.load(), steps=loader.steps_per_epoch)
predictions = [0 if i[0] >= i[1] else 1 for i in predictions]

tpos = 0
fpos = 0
fneg = 0
tneg = 0

for i in range(len(actuals)):
    if actuals[i] ==  1 and predictions[i] == 1:
        tpos += 1
    elif actuals[i] == 0 and predictions[i] == 1:
        fpos += 1
    elif actuals[i] == 1 and predictions[i] == 0:
        fneg += 1
    else:
        tneg += 1

confusion_matrix = [[tpos, fneg], [fpos, tneg]]
print(confusion_matrix)
model.evaluate(loader.load(), steps=loader.steps_per_epoch)
