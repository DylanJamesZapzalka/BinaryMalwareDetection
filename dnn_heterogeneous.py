import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers
from tensorflow.keras.datasets import cifar10
import numpy as np
from matplotlib import pyplot as plt
import sys
np.set_printoptions(threshold=sys.maxsize)


# Constants
EPOCHS = 10
LEARNING_RATE = 0.00001
TRAINING_PERCENTAGE = 0.8



# Load the data
benign_data = np.loadtxt("processed_data/cfg_features/benign.txt").astype("float32")
malicious_data = np.loadtxt("processed_data/cfg_features/malicious.txt").astype("float32")

# Combine and suffle the data
data = np.concatenate((benign_data, malicious_data))
np.random.shuffle(data)

# Split the data into training and testing
training_data = data[0 : int(len(data)*(TRAINING_PERCENTAGE))]
testing_data = data[int(len(data)*(TRAINING_PERCENTAGE)) : len(data)]
print(np.shape(training_data))
print(np.shape(testing_data))
# Split the features and their labels

x_train = np.delete(training_data, np.shape(training_data)[1]-1, 1)
y_train = training_data[:,np.shape(training_data)[1]-1]
x_test = np.delete(testing_data, np.shape(testing_data)[1]-1, 1)
y_test = testing_data[:,np.shape(testing_data)[1]-1]

# Normalize the data
mean = np.mean(x_train, axis=0)
std = np.std(x_train, axis=0)
x_train = (x_train - mean)/(std + 0.0001)
x_test = (x_test - mean)/(std + 0.0001)



# Design the architecture of the netork
inputs = keras.Input(shape=23)                      # Input Layer
x = layers.Dense(2048, activation='relu')(inputs)   # Hidden Layer 1
x = layers.Dense(2048, activation='relu')(x)        # Hidden Layer 2
x = layers.Dense(1024, activation='relu')(x)        # Hidden Layer 3
x = layers.Dense(1024, activation='relu')(x)        # Hidden Layer 4
x = layers.Dense(1024, activation='relu')(x)        # Hidden Layer 5
x = layers.Dense(1024, activation='relu')(x)        # Hidden Layer 6
outputs = layers.Dense(1, activation='sigmoid')(x)  # Output Layer
model = keras.Model(inputs=inputs, outputs=outputs)

# Compile the network
model.compile(
    loss=keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    metrics=["accuracy"]
)

# Train and evaluate the network
training_accuracy = model.fit(x_train, y_train, batch_size=1, epochs=EPOCHS, verbose=2)
training_accuracy = training_accuracy.history['accuracy']
test_accuracy = model.evaluate(x_test, y_test, batch_size=1, verbose=2)
test_accuracy = test_accuracy[1]
predict_labels = (model.predict(x_test) > 0.5).astype("int32")
print(tf.math.confusion_matrix(y_test, predict_labels, num_classes=2))